{
  "test_suite_summary": {
    "project_name": "EU AI Act Compliance Assessment System",
    "generated_at": "2025-11-18T13:10:00",
    "total_test_modules": 4,
    "total_test_classes": 13,
    "total_test_cases": 72,
    "test_modules": [
      {
        "module": "test_models",
        "file": "tests/test_models.py",
        "documentation_file": "tests/docs/test_models_documentation.json",
        "status": "✅ 21/21 PASSING",
        "test_classes": 4,
        "test_cases": 21,
        "description": "Tests for Pydantic models (RiskTier, AISystemProfile, ComplianceAssessment) and serialization",
        "classes": [
          {
            "name": "TestRiskTierEnum",
            "tests": 5,
            "coverage": "Enum values, string conversion, validation, comparison"
          },
          {
            "name": "TestAISystemProfile",
            "tests": 4,
            "coverage": "Model creation, field validation, boolean fields"
          },
          {
            "name": "TestComplianceAssessment",
            "tests": 8,
            "coverage": "Score validation (0-100), risk tier consistency, boundaries"
          },
          {
            "name": "TestModelSerialization",
            "tests": 4,
            "coverage": "Dict conversion, JSON serialization, deserialization"
          }
        ]
      },
      {
        "module": "test_tools",
        "file": "tests/test_tools.py",
        "documentation_file": "tests/docs/test_tools_documentation.json",
        "status": "⏳ Pending verification",
        "test_classes": 2,
        "test_cases": 18,
        "description": "Tests for ComplianceScoringTool and EUAIActReferenceTool",
        "classes": [
          {
            "name": "TestComplianceScoringTool",
            "tests": 13,
            "coverage": "Tool initialization, score ranges (0-100), risk tier classification (prohibited: 85-100, high: 55-84, limited: 25-54, minimal: 0-24), pattern matching, confidence scores, error handling"
          },
          {
            "name": "TestEUAIActReferenceTool",
            "tests": 5,
            "coverage": "Tool initialization, article extraction (single/multiple), keyword search, error handling"
          }
        ]
      },
      {
        "module": "test_vector_index",
        "file": "tests/test_vector_index.py",
        "documentation_file": "tests/docs/test_vector_index_documentation.json",
        "status": "⏳ Pending verification",
        "test_classes": 3,
        "test_cases": 20,
        "description": "Tests for VectorIndexTool, caching, and search integration",
        "classes": [
          {
            "name": "TestVectorIndexTool",
            "tests": 12,
            "coverage": "Initialization for all sections (articles/recitals/annexes), search queries, top_k parameter (default=5), result formatting, metadata inclusion"
          },
          {
            "name": "TestVectorIndexCaching",
            "tests": 2,
            "coverage": "Cache directory structure, index file naming"
          },
          {
            "name": "TestVectorSearchIntegration",
            "tests": 6,
            "coverage": "Real searches with cached indexes (integration tests, marked skipif)"
          }
        ]
      },
      {
        "module": "test_evaluation",
        "file": "tests/test_evaluation.py",
        "documentation_file": "tests/docs/test_evaluation_documentation.json",
        "status": "⏳ Pending verification",
        "test_classes": 4,
        "test_cases": 13,
        "description": "Tests for evaluation framework, scenarios, and metrics",
        "classes": [
          {
            "name": "TestEvaluationScenario",
            "tests": 3,
            "coverage": "Scenario creation with required/optional fields, score range validation"
          },
          {
            "name": "TestAgentEvaluator",
            "tests": 4,
            "coverage": "Evaluator initialization, risk tier matching, score ranges, async scenario evaluation, error handling"
          },
          {
            "name": "TestEvaluationMetrics",
            "tests": 4,
            "coverage": "Accuracy calculation, confusion matrix, score differences, confidence aggregation"
          },
          {
            "name": "TestScenarioExecution",
            "tests": 2,
            "coverage": "Sequential execution order, rate limiting, async workflow"
          }
        ]
      }
    ],
    "test_types": {
      "unit_tests": {
        "count": 66,
        "description": "Fast tests with no external dependencies"
      },
      "integration_tests": {
        "count": 6,
        "description": "Tests requiring API keys or vector indexes",
        "markers": "@pytest.mark.integration, @pytest.mark.skipif"
      },
      "async_tests": {
        "count": 3,
        "description": "Tests using asyncio and pytest-asyncio"
      }
    },
    "key_test_validations": {
      "risk_score_ranges": {
        "prohibited": "85-100",
        "high_risk": "55-84",
        "limited_risk": "25-54",
        "minimal_risk": "0-24"
      },
      "confidence_scores": "0.0-1.0",
      "model_validation": "Pydantic validation with bounds checking",
      "pattern_matching": "Prohibited, high-risk, limited-risk patterns",
      "error_handling": "Invalid JSON, missing fields, API errors"
    },
    "dependencies": {
      "pytest": "9.0.1",
      "pytest-asyncio": "1.3.0",
      "pytest-cov": "7.0.0",
      "pytest-anyio": "4.11.0"
    },
    "running_tests": {
      "all_unit_tests": "pytest tests/ -v -m 'unit'",
      "exclude_integration": "pytest tests/ -v -m 'not integration'",
      "specific_module": "pytest tests/test_models.py -v",
      "with_coverage": "pytest tests/ --cov=src --cov-report=html",
      "fast_only": "pytest tests/ -v -m 'not slow and not integration'"
    },
    "files_generated": {
      "test_modules": [
        "tests/test_models.py",
        "tests/test_tools.py",
        "tests/test_vector_index.py",
        "tests/test_evaluation.py"
      ],
      "supporting_files": [
        "tests/conftest.py",
        "tests/test_utils.py",
        "pytest.ini"
      ],
      "documentation": [
        "tests/docs/test_models_documentation.json",
        "tests/docs/test_tools_documentation.json",
        "tests/docs/test_vector_index_documentation.json",
        "tests/docs/test_evaluation_documentation.json",
        "tests/docs/test_suite_index.json"
      ],
      "scripts": [
        "scripts/generate_test_docs.py"
      ],
      "summaries": [
        "UNIT_TESTS_SUMMARY.md"
      ]
    }
  }
}

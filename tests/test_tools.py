"""Unit tests for tools_adk.py - ComplianceScoringTool and EUAIActReferenceTool."""

import pytest
from unittest.mock import Mock, patch
from src.tools_adk import ComplianceScoringTool, EUAIActReferenceTool
from src.models import RiskTier


class TestComplianceScoringTool:
    """Test suite for ComplianceScoringTool."""
    
    @pytest.fixture
    def scoring_tool(self):
        """Create a ComplianceScoringTool instance for testing."""
        return ComplianceScoringTool()
    
    def test_tool_initialization(self, scoring_tool):
        """Test that tool initializes correctly with proper name and description."""
        assert scoring_tool.name == "compliance_scoring"
        assert "compliance score" in scoring_tool.description.lower()
        assert scoring_tool.framework is not None
    
    def test_framework_has_required_patterns(self, scoring_tool):
        """Test that framework contains all required pattern categories."""
        assert "prohibited_patterns" in scoring_tool.framework
        assert "high_risk_patterns" in scoring_tool.framework
        assert "limited_risk_patterns" in scoring_tool.framework
        assert isinstance(scoring_tool.framework["prohibited_patterns"], list)
    
    def test_score_range_bounds(self, scoring_tool):
        """Test that risk scores are within valid range (0-100)."""
        test_input = '{"system_name": "Test system", "use_case": "Testing"}'
        result = scoring_tool.execute(test_input)
        
        # Extract score from result string
        import json
        result_dict = json.loads(result)
        score = result_dict.get("score", 0)
        
        assert 0 <= score <= 100, f"Score {score} out of valid range"
    
    def test_prohibited_system_high_score(self, scoring_tool):
        """Test that prohibited systems get very high risk scores (85+)."""
        prohibited_input = '''{
            "system_name": "Mass Surveillance System",
            "use_case": "Real-time biometric facial recognition for mass surveillance and social scoring by government",
            "data_types": ["biometric", "personal_data"],
            "autonomous_decision": true,
            "decision_impact": "significant"
        }'''
        
        result = scoring_tool.execute(prohibited_input)
        import json
        result_dict = json.loads(result)
        score = result_dict["score"]
        
        assert score >= 85, f"Prohibited system scored {score}, expected >= 85"
    
    def test_high_risk_system_appropriate_score(self, scoring_tool):
        """Test that high-risk systems get scores in 55-84 range."""
        high_risk_input = '''{
            "system_name": "Employment Screening System",
            "use_case": "AI system for recruitment and hiring decisions",
            "data_types": ["personal_data", "employment_data"],
            "decision_impact": "significant",
            "autonomous_decision": true
        }'''
        
        result = scoring_tool.execute(high_risk_input)
        import json
        result_dict = json.loads(result)
        score = result_dict["score"]
        
        assert 55 <= score < 85, f"High-risk system scored {score}, expected 55-84"
    
    def test_limited_risk_system_appropriate_score(self, scoring_tool):
        """Test that limited-risk systems get scores in 25-54 range."""
        limited_risk_input = '''{
            "system_name": "Customer Service Chatbot",
            "use_case": "automated customer support chatbot",
            "data_types": ["conversation_data"],
            "autonomous_decision": false,
            "human_oversight": true
        }'''
        
        result = scoring_tool.execute(limited_risk_input)
        import json
        result_dict = json.loads(result)
        score = result_dict["score"]
        
        assert 25 <= score < 55, f"Limited-risk system scored {score}, expected 25-54"
    
    def test_minimal_risk_system_low_score(self, scoring_tool):
        """Test that minimal-risk systems get low scores (< 25)."""
        minimal_risk_input = '''{
            "system_name": "Spam Filter",
            "use_case": "email filtering",
            "data_types": ["email_content"],
            "decision_impact": "minimal",
            "autonomous_decision": true
        }'''
        
        result = scoring_tool.execute(minimal_risk_input)
        import json
        result_dict = json.loads(result)
        score = result_dict["score"]
        
        assert score < 25, f"Minimal-risk system scored {score}, expected < 25"
    
    def test_confidence_score_in_valid_range(self, scoring_tool):
        """Test that confidence scores are between 0 and 1."""
        test_input = '{"system_name": "Test", "use_case": "Testing"}'
        result = scoring_tool.execute(test_input)
        
        import json
        result_dict = json.loads(result)
        # Note: ADK tool doesn't return confidence_score, skip this test or remove
        # For now, just check result is valid
        assert "score" in result_dict
        assert "classification" in result_dict
    
    def test_result_contains_required_fields(self, scoring_tool):
        """Test that result contains all required fields."""
        test_input = '{"system_name": "Test system", "use_case": "Testing"}'
        result = scoring_tool.execute(test_input)
        
        import json
        result_dict = json.loads(result)
        
        # ADK tool returns: score, classification, relevant_articles
        assert "score" in result_dict
        assert "classification" in result_dict
        assert "relevant_articles" in result_dict
        assert "origin" in result_dict
    
    def test_pattern_matching_prohibited(self, scoring_tool):
        """Test that prohibited patterns are correctly identified."""
        patterns = scoring_tool.framework["prohibited_patterns"]
        
        # Check that key prohibited patterns exist (match actual patterns in framework)
        assert any("social credit" in p.lower() for p in patterns)
        assert any("surveillance" in p.lower() for p in patterns)
        assert any("manipulation" in p.lower() or "subliminal" in p.lower() for p in patterns)
    
    def test_pattern_matching_high_risk(self, scoring_tool):
        """Test that high-risk patterns are correctly identified."""
        patterns = scoring_tool.framework["high_risk_patterns"]
        
        # Check that key high-risk patterns exist
        assert any("employment" in p.lower() or "recruitment" in p.lower() for p in patterns)
        assert any("credit" in p.lower() or "creditworthiness" in p.lower() for p in patterns)
        assert any("law enforcement" in p.lower() for p in patterns)
    
    def test_json_parsing_error_handling(self, scoring_tool):
        """Test that tool handles invalid JSON gracefully."""
        invalid_json = "This is not valid JSON"
        
        # Should not raise exception, should return error in result
        result = scoring_tool.execute(invalid_json)
        assert result is not None
        assert "error" in result.lower()


class TestEUAIActReferenceTool:
    """Test suite for EUAIActReferenceTool."""
    
    @pytest.fixture
    def reference_tool(self):
        """Create an EUAIActReferenceTool instance for testing."""
        return EUAIActReferenceTool()
    
    def test_tool_initialization(self, reference_tool):
        """Test that tool initializes correctly."""
        assert reference_tool.name == "eu_ai_act_reference"
        assert "EU AI Act" in reference_tool.description
        assert reference_tool.articles is not None
    
    def test_article_extraction(self, reference_tool):
        """Test that specific articles can be extracted."""
        # Test for Article 5 (prohibited practices)
        result = reference_tool.execute('{"action": "get_article", "article_id": "Article 5"}')
        
        assert "Article 5" in result
        assert len(result) > 100  # Should contain substantial content
    
    def test_multiple_articles_extraction(self, reference_tool):
        """Test extracting multiple articles by searching."""
        # Use search action to find multiple articles
        result = reference_tool.execute('{"action": "search_articles", "keyword": "risk"}')
        
        # Should return articles related to "risk"
        assert len(result) > 0
        assert "articles" in result.lower() or "Article" in result
    
    def test_keyword_search(self, reference_tool):
        """Test keyword-based search functionality."""
        result = reference_tool.execute('{"action": "search_articles", "keyword": "high-risk"}')
        
        assert len(result) > 0
        assert "high" in result.lower() or "risk" in result.lower()
    
    def test_invalid_article_number(self, reference_tool):
        """Test handling of invalid article numbers."""
        result = reference_tool.execute('{"action": "get_article", "article_id": "Article 999"}')
        
        # Should handle gracefully with error message
        assert result is not None
        assert "error" in result.lower() or "not found" in result.lower()
    
    def test_empty_query_handling(self, reference_tool):
        """Test handling of empty queries."""
        result = reference_tool.execute('{}')
        
        # Should return search results (defaults to search_articles)
        assert result is not None
        assert len(result) > 0


if __name__ == "__main__":
    # Generate test documentation JSON
    from test_utils import generate_test_documentation, save_test_documentation
    
    test_classes = [
        TestComplianceScoringTool,
        TestEUAIActReferenceTool
    ]
    
    docs = generate_test_documentation(__file__, test_classes)
    json_path = save_test_documentation(docs)
    print(f"\nâœ… Test documentation generated: {json_path}\n")
    
    # Run tests
    pytest.main([__file__, "-v"])
